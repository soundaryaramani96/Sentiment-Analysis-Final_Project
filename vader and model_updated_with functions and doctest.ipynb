"""
Gauging user perception using sentiment analysis
IS590PR by Professor John Weible
Srikanth Pendyala sp22@illinois.edu
Soundarya Ramani sramani3@illinois.edu
Yashi Gupta yashi2@illinois.edu
"""

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_sentiment(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" This function is assigning a sentiment\n",
    "    :param df: pd.DataFrame\n",
    "    >>> new = vader_sentiment(df)\n",
    "    >>> new['Vader Sentiment'][0] = 'Positive' \"\"\"\n",
    "    scores = []\n",
    "    for items in df['Review']:\n",
    "        score = analyser.polarity_scores(items)\n",
    "        scores.append(score)\n",
    "        final = []\n",
    "    for items in scores:\n",
    "        if items['compound'] >= 0.05:\n",
    "            final.append(\"Positive\")\n",
    "        elif items['compound'] <= -0.05:\n",
    "            final.append(\"Negative\")\n",
    "        else:\n",
    "            final.append(\"Neutral\")\n",
    "    final = pd.DataFrame(final,columns = ['Vader Sentiment'])\n",
    "    df['Vader Sentiment'] = final\n",
    "    df.head()\n",
    "    df.to_csv(\"C:/Users/srikanth/PycharmProjects/PR Project/Vader Sentiment PlayStore.csv\", encoding='utf-8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Data as Training & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdtpa(train_text,test_text):\n",
    "    \"\"\" This function  is Dropping Nulls\n",
    "    :param df: pd.DataFrame\n",
    "    >>> new = sdtpa(train_text, test_text)\n",
    "    >>> Train_text['Review'] = [entry.lower() for entry in Train_text['Review'] \"\"\"\n",
    "    #Data Preprocessing: a.Dropping Nulls\n",
    "    train_text['Review'].dropna(inplace=True)\n",
    "    test_text['Review'].dropna(inplace=True)\n",
    "    return train_text, test_text\n",
    "    \n",
    "    #Train_text['Review'] = [entry.lower() for entry in Train_text['Review']]\n",
    "    #Test_text['Review'] = [entry.lower() for entry in Test_text['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdtpb(train_test, test_text):\n",
    "    \"\"\" This function is Converting Data to Lowercase\n",
    "    :param df: pd.DataFrame\n",
    "    >>> new = sdtpb(train_text, test_text)\n",
    "    >>> Train_text['Review'] = [entry.lower() for b.Converting Data to Lowercase] \"\"\"\n",
    "    #Data Preprocessing: b.Converting Data to Lowercase\n",
    "    train_text['Review'] = [entry.lower() for entry in train_text['Review']]\n",
    "    test_text['Review'] = [entry.lower() for entry in test_text['Review']]\n",
    "    return train_text, test_text \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdtpc(train_text, test_text):\n",
    "    \"\"\" :param train_test: pd.DataFrame\n",
    "    :param test_text: pd.DataFrame\n",
    "    >>>one = sdtpc(train_text, test_text)\n",
    "    \"\"\"\n",
    "    # Data Preprocessing: c.Tokenizing Data\n",
    "    train_text['Review']= [word_tokenize(entry) for entry in train_text['Review']]\n",
    "    test_text['Review']= [word_tokenize(entry) for entry in test_text['Review']]\n",
    "    return train_text, test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdtpd(train_text, test_text):\n",
    "    \"\"\" This function is Tagging Words to their Types\n",
    "    :param df: pd.DataFrame\n",
    "    >>> new = sdtpd(train_text, test_text)\n",
    "    >>> Train_text['Review'] = [entry.lower() for d.Tagging Words to their Types] \"\"\"\n",
    "    # Data Preprocessing: d.Tagging Words to their Types\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    return tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdtpe(train_text, test_text, tag_map):\n",
    "    \"\"\" This function is Lemmatizing Training Data and Removing Stopwords\n",
    "    :param df: pd.DataFrame\n",
    "    >>> new = sdtpe(train_text, test_text)\n",
    "    >>> Train_text['Review'] = [entry.lower() for e.Lemmatizing Training Data and Removing Stopwords] \"\"\"\n",
    "    # Data Preprocessing: e.Lemmatizing Training Data and Removing Stopwords\n",
    "    big_list = []\n",
    "    for index,entry in enumerate(train_text['Review']):\n",
    "    #Declaring Empty List to store the words that follow the rules for this step\n",
    "        Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "        word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "        for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "            if word not in stopwords.words('english') and word.isalpha():\n",
    "                word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "                Final_words.append(word_Final)\n",
    "        big_list.append(Final_words)\n",
    "    # Bringing Training Data to Correct Format\n",
    "    train_text = pd.Series(str(items) for items in big_list)\n",
    "    # Data Preprocessing: e.Lemmatizing Test Data and Removing Stopwords\n",
    "\n",
    "    big_list_1 = []\n",
    "    for index,entry in enumerate(test_text['Review']):\n",
    "    #Declaring Empty List to store the words that follow the rules for this step\n",
    "        Final_words = []\n",
    "    #Initializing WordNetLemmatizer()\n",
    "        word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "        for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "            if word not in stopwords.words('english') and word.isalpha():\n",
    "                word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "                Final_words.append(word_Final)\n",
    "        big_list_1.append(Final_words)\n",
    "    # Bringing Test Data to Correct Format\n",
    "    test_text = pd.Series(str(items) for items in big_list_1)\n",
    "    return train_text, test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(train_text, test_text):\n",
    "    \"\"\" This function is Generating A Total Corpus of Words\n",
    "    :param df: pd.DataFrame\n",
    "    >>> new = sdtpe(train_text, test_text)\n",
    "    >>> Train_text['Review'] = [entry.lower() for Generating A Total Corpus of Words] \"\"\"\n",
    "    # Generating A Total Corpus of Words\n",
    "    all_texts = []\n",
    "    for items in train_text:\n",
    "        all_texts.append(items)\n",
    "\n",
    "    for items in test_text:\n",
    "        all_texts.append(items)\n",
    "    return all_texts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(train_labels, test_labels):\n",
    "    \"\"\" This function is Encoding label\n",
    "    :param df: pd.DataFrame\n",
    "    >>> new = label_encoding(train_labels, test_labels)\n",
    "    >>> Encoder['Review'] = [LabelEncoder() for Label Encoding] \"\"\"\n",
    "    # Label Encoding\n",
    "    Encoder = LabelEncoder()\n",
    "    train_labels = Encoder.fit_transform(Train_labels)\n",
    "    test_labels = Encoder.fit_transform(Test_labels)\n",
    "    return train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectors as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting_features(train_text, test_text, all_texts):\n",
    "     \"\"\"This function is to create a vectorized object, transforming the training and validation\n",
    "    data using count vectorizer object and to calcilate word level and ngram level tf-idf\n",
    "    :param train_text: pd.DataFrame\n",
    "    :param test_text: pd.DataFrame\n",
    "    :param all_texts: list\n",
    "    >>> sel = selecting_features(train_text, test_text, all_texts)\n",
    "    \"\"\"\n",
    "    # create a count vectorizer object \n",
    "    count_vect = CountVectorizer(analyzer='word')\n",
    "    count_vect.fit(all_texts)\n",
    "\n",
    "    # transform the training and validation data using count vectorizer object\n",
    "    xtrain_count =  count_vect.transform(train_text)\n",
    "    xvalid_count =  count_vect.transform(test_text)\n",
    "    \n",
    "    # word level tf-idf\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word',max_features=5000)\n",
    "    tfidf_vect.fit(all_texts)\n",
    "    xtrain_tfidf =  tfidf_vect.transform(train_text)\n",
    "    xvalid_tfidf =  tfidf_vect.transform(test_text)\n",
    "    \n",
    "    # ngram level tf-idf \n",
    "    tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=5000)\n",
    "    tfidf_vect_ngram.fit(all_texts)\n",
    "    xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_text)\n",
    "    xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(test_text)\n",
    "    return xtrain_count, xvalid_count,xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Function to Deploy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False,test_labels1):\n",
    "     \"\"\" This function is Encoding label\n",
    "    :param classifier:\n",
    "    :param feature_vector_train:\n",
    "    :param label:\n",
    "    :param feature_vector_valid:\n",
    "    :param is_neural_net=False,test_labels1:\n",
    "    >>> new = train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False,test_labels1)\n",
    "    >>>train_model['Review'] = [classifier.fit() for training model] \"\"\"\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels):\n",
    "    \"\"\"This function is for training the model according to naive bayes concept\n",
    "    :param xtrain_count: list\n",
    "    :param xvalid_count: list\n",
    "    :param xtrain_tfidf: list\n",
    "    :param xvalid_tfidf:list\n",
    "    :param xtrain_tfidf_ngram:list\n",
    "    :param xvalid_tfidf_ngram: list\n",
    "    \n",
    "    >>> nb = naive(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels)\"\"\"\n",
    "    \n",
    "    # Naive Bayes on Count Vectors\n",
    "    accuracy_count_nb = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_labels, xvalid_count)\n",
    "    print (\"NB, Count Vectors: \", accuracy_count_nb)\n",
    "\n",
    "    # Naive Bayes on Word Level TF IDF Vectors\n",
    "    accuracy_word_nb = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "    print (\"NB, WordLevel TF-IDF: \", accuracy_word_nb)\n",
    "\n",
    "    # Naive Bayes on Ngram Level TF IDF Vectors\n",
    "    accuracy_ngram_nb = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_labels, xvalid_tfidf_ngram)\n",
    "    print (\"NB, N-Gram Vectors: \", accuracy_ngram_nb)\n",
    "    return accuracy_count_nb, accuracy_word_nb, accuracy_ngram_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels):\n",
    "    \"\"\" This function is Random Forest on Count Vectors\n",
    "    :param list:\n",
    "    >>> new = random_forest(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels)\n",
    "    >>> random_forest['Review'] = [LabelEncoder() for Random Forest on Count Vectors] \"\"\"\n",
    "    #Random Forest on Count Vectors\n",
    "    accuracy_count_rf = train_model(RandomForestClassifier(n_estimators=100),xtrain_count,train_labels,xvalid_count)\n",
    "    #print(\"RF, Count Vectors: \",accuracy_count_rf)\n",
    "\n",
    "    #Random Forest on Word Level TF IDF Vectors\n",
    "    accuracy_word_rf = train_model(RandomForestClassifier(n_estimators=100),xtrain_tfidf,train_labels,xvalid_tfidf)\n",
    "    #print(\"RF, WordLevel TF-IDF Vectors: \",accuracy_word_rf)\n",
    "\n",
    "    #Random Forest Ngram Level TF IDF Vectors\n",
    "    accuracy_ngram_rf = train_model(RandomForestClassifier(n_estimators=100),xtrain_tfidf_ngram,train_labels,xvalid_tfidf_ngram)\n",
    "    #print(\"RF, N-Gram Vectors: \",accuracy_ngram_rf)\n",
    "    return accuracy_count_rf, accuracy_word_rf, accuracy_ngram_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels):\n",
    "    \"\"\"this function is for logistic regression\n",
    "    :param xtrain_count: list\n",
    "    :param xvalid_count: list\n",
    "    :param xtrain_tfidf: list\n",
    "    :param xvalid_tfidf:list\n",
    "    :param xtrain_tfidf_ngram:list\n",
    "    :param xvalid_tfidf_ngram: list\n",
    "    >>> lr = logistic_regression(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels):\n",
    "    \"\"\"\n",
    "    # Linear Classifier on Count Vectors\n",
    "    accuracy_count_lc = train_model(linear_model.LogisticRegression(), xtrain_count, train_labels, xvalid_count)\n",
    "    #print (\"LR, Count Vectors: \", accuracy_count_lc)\n",
    "\n",
    "    # Linear Classifier on Word Level TF IDF Vectors\n",
    "    accuracy_word_lc = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "    #print (\"LR, WordLevel TF-IDF: \", accuracy_word_lc)\n",
    "\n",
    "    # Linear Classifier on Ngram Level TF IDF Vectorstrain_labels\n",
    "    accuracy_ngram_lc = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_labels, xvalid_tfidf_ngram)\n",
    "    #print (\"LR, N-Gram Vectors: \", accuracy_ngram_lc)\n",
    "    return accuracy_count_lc, accuracy_word_lc, accuracy_ngram_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels):\n",
    "     \"\"\"This function is for SVM\n",
    "    :param xtrain_count: list\n",
    "    :param xvalid_count: list\n",
    "    :param xtrain_tfidf: list\n",
    "    :param xvalid_tfidf: list\n",
    "    :param xtrain_tfidf_ngram: list\n",
    "    :param xvalid_tfidf_ngram: list\n",
    "    >>> s = svm(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels)\n",
    "    \"\"\"\n",
    "    # SVM on Count Vectors Linear Kernel\n",
    "    accuracy_count_svm = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_count, train_labels, xvalid_count)\n",
    "    #print (\"SVM,Count Vectors: \", accuracy_count_svm)\n",
    "\n",
    "    # SVM on Word Level TF-IDF Vectors Linear Kernel\n",
    "    accuracy_word_svm = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "    #print (\"SVM, Word Level TF-IDF Vectors: \", accuracy_word_svm)\n",
    "\n",
    "    # SVM on Ngram Level TF IDF Vectors  Linear Kernel\n",
    "    accuracy_ngram_svm = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_tfidf_ngram, train_labels, xvalid_tfidf_ngram)\n",
    "    #print (\"SVM, N-Gram Vectors: \", accuracy_ngram_svm)\n",
    "    return accuracy_count_svm, accuracy_word_svm, accuracy_ngram_svm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels):\n",
    "    \"\"\"this function is for bagging and uses 6 lists as parameters\n",
    "    :param xtrain_count: list\n",
    "    :param xvalid_count: list\n",
    "    :param xtrain_tfidf: list\n",
    "    :param xvalid_tfidf: list\n",
    "    :param xtrain_tfidf_ngram: list\n",
    "    :param xvalid_tfidf_ngram: list\n",
    "    >>> bg = bagging(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels):\"\"\"\n",
    "    # RF on Count Vectors\n",
    "    accuracy_count_bg = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_labels, xvalid_count)\n",
    "    #print (\"RF, Count Vectors: \", accuracy_count_bg)\n",
    "\n",
    "    # RF on Word Level TF IDF Vectors\n",
    "    accuracy_word_bg = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "    #print (\"RF, WordLevel TF-IDF: \", accuracy_word_bg)\n",
    "\n",
    "    # RF on Ngram Vectors\n",
    "    accuracy_ngram_bg = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_labels, xvalid_tfidf_ngram)\n",
    "    #print (\"RF, Ngram Vectors: \", accuracy_ngram_bg)\n",
    "    return accuracy_count_bg, accuracy_word_bg, accuracy_ngram_bg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels):\n",
    "    \"\"\"function for boosting\n",
    "    :param xtrain_count: list\n",
    "    :param xvalid_count: list\n",
    "    :param xtrain_tfidf:list\n",
    "    :param xvalid_tfidf: list\n",
    "    :param xtrain_tfidf_ngram: list\n",
    "    :param xvalid_tfidf_ngram: list\n",
    "    >>> boos =boosting(xtrain_count, xvalid_count, xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels): \"\"\"\n",
    "    # Extereme Gradient Boosting on Count Vectors\n",
    "    accuracy_count_bo = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_labels, xvalid_count.tocsc())\n",
    "    #print (\"Xgb, Count Vectors: \", accuracy_count_bo)\n",
    "\n",
    "    # Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "    accuracy_word_bo = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_labels, xvalid_tfidf.tocsc())\n",
    "    #print (\"Xgb, WordLevel TF-IDF: \", accuracy_word_bo)\n",
    "\n",
    "    # Extereme Gradient Boosting on NGRAM Level TF IDF Vectors\n",
    "    accuracy_ngram_bo = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram.tocsc(), train_labels, xvalid_tfidf_ngram.tocsc())\n",
    "    #print (\"Xgb, Ngram Level Vectors: \", accuracy_ngram_bo)\n",
    "    return accuracy_count_bo, accuracy_word_bo, accuracy_ngram_bo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_summary(accuracy_count_nb, accuracy_count_rf, accuracy_count_lc, accuracy_count_svm, accuracy_count_bg, accuracy_count_bo):\n",
    "    \"\"\" This function is to determine accurarcy\n",
    "    :param list:\n",
    "    >>> new = count_summary(accuracy_count_nb, accuracy_count_rf, accuracy_count_lc, accuracy_count_svm, accuracy_count_bg, accuracy_count_bo)\n",
    "    >>> count_summary['Review'] = [ accuracy_nb() for accurarcy] \"\"\"\n",
    "    accuracy_nb = round(accuracy_count_nb*100,2)\n",
    "    accuracy_rf = round(accuracy_count_rf*100,2)\n",
    "    accuracy_lc = round(accuracy_count_lc*100,2)\n",
    "    accuracy_svm = round(accuracy_count_svm*100,2)\n",
    "    accuracy_bg = round(accuracy_count_bg*100,2)\n",
    "    accuracy_bo = round(accuracy_count_bo*100,2)\n",
    "    return accuracy_nb, accuracy_rf, accuracy_lc, accuracy_svm, accuracy_bg, accuracy_bo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_summary(accuracy_word_nb, accuracy_word_rf, accuracy_word_lc, accuracy_word_svm, accuracy_word_bg, accuracy_word_bo):\n",
    "    \"\"\" This function is to determine word summary\n",
    "    :param list:\n",
    "    >>> new = word_summary(accuracy_count_nb, accuracy_count_rf, accuracy_count_lc, accuracy_count_svm, accuracy_count_bg, accuracy_count_bo)\n",
    "    >>> word_summary['Review'] = [ accuracy_wnb() for word summary] \"\"\"\n",
    "    accuracy_wnb = round(accuracy_word_nb*100,2)\n",
    "    accuracy_wrf = round(accuracy_word_rf*100,2)\n",
    "    accuracy_wlc = round(accuracy_word_lc*100,2)\n",
    "    accuracy_wsvm = round(accuracy_word_svm*100,2)\n",
    "    accuracy_wbg = round(accuracy_word_bg*100,2)\n",
    "    accuracy_wbo = round(accuracy_word_bo*100,2)\n",
    "    return accuracy_wnb, accuracy_wrf, accuracy_wlc, accuracy_wsvm, accuracy_wbg, accuracy_wbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_summary(accuracy_ngram_nb, accuracy_ngram_rf, accuracy_ngram_lc, accuracy_ngram_svm, accuracy_ngram_bg, accuracy_ngram_bo):\n",
    "     \"\"\" This function is to determine ngram_nb\n",
    "    :param list:\n",
    "    >>> new = ngram_summary(accuracy_count_nb, accuracy_count_rf, accuracy_count_lc, accuracy_count_svm, accuracy_count_bg, accuracy_count_bo)\n",
    "    >>>ngram_summary['Review'] = [  ngram_nb() for word summary] \"\"\"\n",
    "    ngram_nb = round(accuracy_ngram_nb*100,2)\n",
    "    ngram_rf = round(accuracy_ngram_rf*100,2)\n",
    "    ngram_lc = round(accuracy_ngram_lc*100,2)\n",
    "    ngram_svm = round(accuracy_ngram_svm*100,2)\n",
    "    ngram_bg = round(accuracy_ngram_bg*100,2)\n",
    "    ngram_bo = round(accuracy_ngram_bo*100,2)\n",
    "    return ngram_nb, ngram_rf, ngram_lc, ngram_svm, ngram_bg, ngram_bo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='linear'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(X, y, clf, title):\n",
    "\n",
    "    cm = metrics.confusion_matrix(y, clf.predict(X))\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "    mpl.rc(\"figure\", figsize=(8, 4))\n",
    "\n",
    "    hm = sns.heatmap(cm, \n",
    "            cbar=False,\n",
    "            annot=True, \n",
    "            square=True,\n",
    "            fmt='d',\n",
    "            yticklabels=['negative','neutral','positive'],\n",
    "            xticklabels=['negative','neutral','positive'],\n",
    "            cmap='Blues'\n",
    "            )\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Actual class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #main data set into a dataframe\n",
    "    dataset = pd.read_csv(\"playstore_data.csv\",header=0,encoding='utf-8')\n",
    "    df = dataset.copy()\n",
    "    #function call for the vader_sentiment function and updating the existing data frame\n",
    "    updated_df = vader_sentiment(df)\n",
    "    #processing the next function for Sentiment data as Training and Preprocessing:\n",
    "    text_data = df['Review']\n",
    "    label_data = df['Vader Sentiment']\n",
    "    text_data = pd.DataFrame(text_data,columns=['Review'])\n",
    "    label_data = pd.DataFrame(label_data,columns=['Vader Sentiment'])\n",
    "    train_text, test_text, train_labels, test_labels = train_test_split(text_data, label_data, test_size=0.2,shuffle=False)\n",
    "    #function call for sdtpa:\n",
    "    train_text_1, test_text1 = sdtpa(train_text, test_text)\n",
    "    display(train_text1,test_text1)\n",
    "    #function call for sdtpb:\n",
    "    train_text2, test_text2 = sdtpb(train_text1, test_text1)\n",
    "    display(train_text2, test_text2)\n",
    "    #function call for sdtpc:\n",
    "    train_text3, test_text3 = sdtpc(train_text2, test_text2)\n",
    "    display(train_text3, test_text3)\n",
    "    #function call for sdtpd:\n",
    "    tag_map = sdtpd(train_text3, test_text3)\n",
    "    #function call for sdtpe:\n",
    "    train_text4, test_text4 = sdtpe(train_text3, test_text3, tag_map)\n",
    "    display(train_text4, test_text4)\n",
    "    #function call for total_words:\n",
    "    all_texts = total_words(train_text4, test_text4)\n",
    "    #function call for label_encoding:\n",
    "    train_labels1, test_labels1 = label_encoding(train_labels, test_labels)\n",
    "    #function_call for selecting_features:\n",
    "    xtrain_count, xvalid_count,xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram = selecting_features(train_text, test_text, all_texts)\n",
    "    #calling the naive bayes function:\n",
    "    accuracy_count_nb, accuracy_word_nb, accuracy_ngram_nb = naive(xtrain_count, xvalid_count,xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels1)\n",
    "    print (\"NB, Count Vectors: \", accuracy_count_nb)\n",
    "    print (\"NB, WordLevel TF-IDF: \", accuracy_word_nb)\n",
    "    print (\"NB, N-Gram Vectors: \", accuracy_ngram_nb)\n",
    "\n",
    "    #random forest function call\n",
    "    accuracy_count_rf, accuracy_word_rf, accuracy_ngram_rf = random_forest(xtrain_count, xvalid_count,xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels1)\n",
    "    print(\"RF, Count Vectors: \",accuracy_count_rf)\n",
    "    print(\"RF, WordLevel TF-IDF Vectors: \",accuracy_word_rf)\n",
    "    print(\"RF, N-Gram Vectors: \",accuracy_ngram_rf)\n",
    "\n",
    "    #logistic_regression function call\n",
    "    accuracy_count_lc, accuracy_word_lc, accuracy_ngram_lc = logistic_regression(xtrain_count, xvalid_count,xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels1)\n",
    "    print (\"LR, Count Vectors: \", accuracy_count_lc)\n",
    "    print (\"LR, WordLevel TF-IDF: \", accuracy_word_lc)\n",
    "    print (\"LR, N-Gram Vectors: \", accuracy_ngram_lc)\n",
    "\n",
    "    \n",
    "    #SVM function call:\n",
    "    accuracy_count_svm, accuracy_word_svm, accuracy_ngram_svm = svm(xtrain_count, xvalid_count,xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels1)\n",
    "    print (\"SVM,Count Vectors: \", accuracy_count_svm)\n",
    "    print (\"SVM, Word Level TF-IDF Vectors: \", accuracy_word_svm)\n",
    "    print (\"SVM, N-Gram Vectors: \", accuracy_ngram_svm)\n",
    "\n",
    "    \n",
    "    #function_call for bagging:\n",
    "    accuracy_count_bg, accuracy_word_bg, accuracy_ngram_bg = bagging(xtrain_count, xvalid_count,xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels1)\n",
    "    print (\"RF, Count Vectors: \", accuracy_count_bg)\n",
    "    print (\"RF, WordLevel TF-IDF: \", accuracy_word_bg)\n",
    "    print (\"RF, Ngram Vectors: \", accuracy_ngram_bg)\n",
    "\n",
    "    \n",
    "    #function call for boosting\n",
    "    accuracy_count_bo, accuracy_word_bo, accuracy_ngram_bo = boosting(xtrain_count, xvalid_count,xtrain_tfidf, xvalid_tfidf, xtrain_tfidf_ngram, xvalid_tfidf_ngram, train_labels1)\n",
    "    print (\"Xgb, Count Vectors: \", accuracy_count_bo)\n",
    "    print (\"Xgb, WordLevel TF-IDF: \", accuracy_word_bo)\n",
    "    print (\"Xgb, Ngram Level Vectors: \", accuracy_ngram_bo)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #function call for count_summary:\n",
    "    accuracy_nb, accuracy_rf, accuracy_lc, accuracy_svm, accuracy_bg, accuracy_bo = count_summary(accuracy_count_nb, accuracy_count_rf, accuracy_count_lc, accuracy_count_svm, accuracy_count_bg, accuracy_count_bo)\n",
    "    print('Naive Bayes Classifier')\n",
    "    print (\"NB, Count Vectors: \", accuracy_nb, \"%\")\n",
    "    print(\"\")\n",
    "    \n",
    "    print('Random Forest Classifier')\n",
    "    print(\"RF, Count Vectors: \",accuracy_rf, \"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Linear Classifier')\n",
    "    print (\"LR, Count Vectors: \", accuracy_lc, \"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('SVM Classifier')\n",
    "    print (\"SVM,Count Vectors: \", accuracy_svm, \"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Bagging Classifier')\n",
    "    print (\"RF, Count Vectors: \", accuracy_bg, \"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Boosting Classifier')\n",
    "    print (\"Xgb, Count Vectors: \", accuracy_bo, \"%\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    #function call for word summary:\n",
    "    accuracy_wnb, accuracy_wrf, accuracy_wlc, accuracy_wsvm, accuracy_wbg, accuracy_wbo = word_summary(accuracy_word_nb, accuracy_word_rf, accuracy_word_lc, accuracy_word_svm, accuracy_word_bg, accuracy_word_bo)\n",
    "    print('Naive Bayes Classifier')\n",
    "    print (\"NB, WordLevel TF-IDF: \", accuracy_wnb,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Random Forest Classifier')\n",
    "    print(\"RF, WordLevel TF-IDF Vectors: \",accuracy_wrf,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Linear Classifier')\n",
    "    print (\"LR, WordLevel TF-IDF: \", accuracy_wlc,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('SVM Classifier')\n",
    "    print (\"SVM, Word Level TF-IDF Vectors: \", accuracy_wsvm,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Bagging Classifier')\n",
    "    print (\"RF, WordLevel TF-IDF: \", accuracy_wbg,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Boosting Classifier')\n",
    "    print (\"Xgb, WordLevel TF-IDF: \", accuracy_wbo,\"%\")\n",
    "    print(\"\")\n",
    "    \n",
    "    #function call for ngram summary:\n",
    "    ngram_nb, ngram_rf, ngram_lc, ngram_svm, ngram_bg, ngram_bo = ngram_summary(accuracy_ngram_nb, accuracy_ngram_rf, accuracy_ngram_lc, accuracy_ngram_svm, accuracy_ngram_bg, accuracy_ngram_bo)\n",
    "    print('Naive Bayes Classifier')\n",
    "    print (\"NB, Ngram Vectors: \", ngram_nb,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Random Forest Classifier')\n",
    "    print(\"RF, Ngram Vectors: \",ngram_rf,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Linear Classifier')\n",
    "    print (\"LR, Ngram Vectors: \", ngram_lc,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('SVM Classifier')\n",
    "    print (\"SVM, Ngram Vectors: \", ngram_svm,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Bagging Classifier')\n",
    "    print (\"RF, Ngram Vectors: \", ngram_bg,\"%\")\n",
    "    print(\"\")\n",
    "\n",
    "    print('Boosting Classifier')\n",
    "    print (\"Xgb, Ngram Vectors: \", ngram_bo,\"%\")\n",
    "    print(\"\")\n",
    "    \n",
    "    #\n",
    "    \n",
    "    #function call for parameter selection:\n",
    "    new = svc_param_selection(xtrain_tfidf,train_labels1,5)\n",
    "    print(new)\n",
    "    # SVM on Word Level TF-IDF Vectors Linear Kernel\n",
    "    accuracy_word_svm = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma=0.001), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "    print (\"SVM, Word Level TF-IDF Vectors: \", round(accuracy_word_svm*100,2),\"%\")\n",
    "    \n",
    "    \n",
    "    #plot_cm function:\n",
    "    claf = svm.SVC(C=1.0, kernel='linear', degree=3, gamma=0.001)\n",
    "    claf.fit(xtrain_tfidf, train_labels1)\n",
    "    plot_cm(xtrain_tfidf, train_labels1, claf, 'Training Word Level - TfidfVectorizer on Support Vector Machine')\n",
    "    #plot_cm test2:\n",
    "    plot_cm(xvalid_tfidf,test_labels1, claf, 'Testing Word Level - TfidfVectorizer on Support Vector Machine')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doctests\n",
    "import doctest\n",
    "doctest.testmod(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
