{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"playstore_data.csv\",header=0,encoding='utf-8')\n",
    "df = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Application</th>\n",
       "      <th>Users</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Approval</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>RealTRG</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Ich finde Spotify sehr gut. Die Lieder haben e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Lokan</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Fix the adaptive icon please ðŸ˜­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Abhilash Ulahannan</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>missing a lot of songs i like, not really a fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Michele LaBlanc</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Overall great app. Love that I can have multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Makara Bedell</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>it's good and all, but ur recent update is tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Application               Users  Stars  Approval  \\\n",
       "0   1     Spotify             RealTRG      5         2   \n",
       "1   2     Spotify               Lokan      1         7   \n",
       "2   3     Spotify  Abhilash Ulahannan      2         1   \n",
       "3   4     Spotify     Michele LaBlanc      4        12   \n",
       "4   5     Spotify       Makara Bedell      5         7   \n",
       "\n",
       "                                              Review  \n",
       "0  Ich finde Spotify sehr gut. Die Lieder haben e...  \n",
       "1                  Fix the adaptive icon please ðŸ˜­  \n",
       "2  missing a lot of songs i like, not really a fa...  \n",
       "3  Overall great app. Love that I can have multip...  \n",
       "4  it's good and all, but ur recent update is tra...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Vader Sentiment Analyzer Method\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Sentiment Scores for our Tweets and Appending them to a list\n",
    "\n",
    "scores = []\n",
    "for items in df['Review']:\n",
    "    score = analyser.polarity_scores(items)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the Scores List which is a list of dictionaries, evaluating the final sentiment based on compound score\n",
    "\n",
    "final = []\n",
    "for items in scores:\n",
    "    if items['compound'] >= 0.05:\n",
    "        final.append(\"Positive\")\n",
    "    elif items['compound'] <= -0.05:\n",
    "        final.append(\"Negative\")\n",
    "    else:\n",
    "        final.append(\"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the Final Sentiment to our Initial Dataset\n",
    "\n",
    "final = pd.DataFrame(final,columns = ['Vader Sentiment'])\n",
    "df['Vader Sentiment'] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Application</th>\n",
       "      <th>Users</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Approval</th>\n",
       "      <th>Review</th>\n",
       "      <th>Vader Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>RealTRG</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Ich finde Spotify sehr gut. Die Lieder haben e...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Lokan</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Fix the adaptive icon please ðŸ˜­</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Abhilash Ulahannan</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>missing a lot of songs i like, not really a fa...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Michele LaBlanc</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Overall great app. Love that I can have multip...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Makara Bedell</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>it's good and all, but ur recent update is tra...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Application               Users  Stars  Approval  \\\n",
       "0   1     Spotify             RealTRG      5         2   \n",
       "1   2     Spotify               Lokan      1         7   \n",
       "2   3     Spotify  Abhilash Ulahannan      2         1   \n",
       "3   4     Spotify     Michele LaBlanc      4        12   \n",
       "4   5     Spotify       Makara Bedell      5         7   \n",
       "\n",
       "                                              Review Vader Sentiment  \n",
       "0  Ich finde Spotify sehr gut. Die Lieder haben e...        Negative  \n",
       "1                  Fix the adaptive icon please ðŸ˜­        Positive  \n",
       "2  missing a lot of songs i like, not really a fa...        Positive  \n",
       "3  Overall great app. Love that I can have multip...        Positive  \n",
       "4  it's good and all, but ur recent update is tra...        Positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Sentiment Tagged Dataset\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv(\"Vader Sentiment PlayStore.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Data as Training & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Independent and Dependent Variables\n",
    "text_data = df['Review']\n",
    "label_data = df['Vader Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list to Dataframes\n",
    "text_data = pd.DataFrame(text_data,columns=['Review'])\n",
    "label_data = pd.DataFrame(label_data,columns=['Vader Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data into Training and Test Sets\n",
    "Train_text, Test_text, Train_labels, Test_labels = train_test_split(text_data, label_data, test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:3896: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing: a.Dropping Nulls\n",
    "\n",
    "Train_text['Review'].dropna(inplace=True)\n",
    "Test_text['Review'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing: b.Converting Data to Lowercase\n",
    "\n",
    "Train_text['Review'] = [entry.lower() for entry in Train_text['Review']]\n",
    "Test_text['Review'] = [entry.lower() for entry in Test_text['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing: c.Tokenizing Data\n",
    "\n",
    "Train_text['Review']= [word_tokenize(entry) for entry in Train_text['Review']]\n",
    "Test_text['Review']= [word_tokenize(entry) for entry in Test_text['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing: d.Tagging Words to their Types\n",
    "\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing: e.Lemmatizing Training Data and Removing Stopwords\n",
    "\n",
    "big_list = []\n",
    "for index,entry in enumerate(Train_text['Review']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    big_list.append(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['ich', 'finde', 'spotify', 'sehr', 'gut', 'di...\n",
       "1                ['fix', 'adaptive', 'icon', 'please']\n",
       "2    ['miss', 'lot', 'song', 'like', 'really', 'fan...\n",
       "3    ['overall', 'great', 'app', 'love', 'multiple'...\n",
       "4    ['good', 'ur', 'recent', 'update', 'trash', 'b...\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bringing Training Data to Correct Format\n",
    "\n",
    "train_text = pd.Series(str(items) for items in big_list)\n",
    "train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing: e.Lemmatizing Test Data and Removing Stopwords\n",
    "\n",
    "big_list_1 = []\n",
    "for index,entry in enumerate(Test_text['Review']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    big_list_1.append(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                ['great', 'music', 'listen', 'world']\n",
       "1    ['work', 'fine', 'shortly', 'late', 'update', ...\n",
       "2    ['listen', 'pandora', 'year', 'best', 'music',...\n",
       "3    ['great', 'somthing', 'u', 'want', 'listen', '...\n",
       "4    ['stop', 'every', 'time', 'minimize', 'go', 'a...\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bringing Test Data to Correct Format\n",
    "\n",
    "test_text = pd.Series(str(items) for items in big_list_1)\n",
    "test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating A Total Corpus of Words\n",
    "\n",
    "all_texts = []\n",
    "for items in train_text:\n",
    "    all_texts.append(items)\n",
    "\n",
    "for items in test_text:\n",
    "    all_texts.append(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "train_labels = Encoder.fit_transform(Train_labels)\n",
    "test_labels = Encoder.fit_transform(Test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectors as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(all_texts)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_text)\n",
    "xvalid_count =  count_vect.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Level TF-IDF as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word',max_features=5000)\n",
    "tfidf_vect.fit(all_texts)\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_text)\n",
    "xvalid_tfidf =  tfidf_vect.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram Level TF-IDF as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(all_texts)\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_text)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Function to Deploy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.7284953768562623\n",
      "NB, WordLevel TF-IDF:  0.7175679462034183\n",
      "NB, N-Gram Vectors:  0.7270944242084617\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy_count_nb = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_labels, xvalid_count)\n",
    "print (\"NB, Count Vectors: \", accuracy_count_nb)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy_word_nb = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy_word_nb)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy_ngram_nb = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_labels, xvalid_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: \", accuracy_ngram_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.7960212944802466\n",
      "RF, WordLevel TF-IDF Vectors:  0.794620341832446\n",
      "RF, N-Gram Vectors:  0.8041468198374895\n"
     ]
    }
   ],
   "source": [
    "#Random Forest on Count Vectors\n",
    "accuracy_count_rf = train_model(RandomForestClassifier(n_estimators=100),xtrain_count,train_labels,xvalid_count)\n",
    "print(\"RF, Count Vectors: \",accuracy_count_rf)\n",
    "\n",
    "#Random Forest on Word Level TF IDF Vectors\n",
    "accuracy_word_rf = train_model(RandomForestClassifier(n_estimators=100),xtrain_tfidf,train_labels,xvalid_tfidf)\n",
    "print(\"RF, WordLevel TF-IDF Vectors: \",accuracy_word_rf)\n",
    "\n",
    "#Random Forest Ngram Level TF IDF Vectors\n",
    "accuracy_ngram_rf = train_model(RandomForestClassifier(n_estimators=100),xtrain_tfidf_ngram,train_labels,xvalid_tfidf_ngram)\n",
    "print(\"RF, N-Gram Vectors: \",accuracy_ngram_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.8327262538526198\n",
      "LR, WordLevel TF-IDF:  0.8147940599607734\n",
      "LR, N-Gram Vectors:  0.8097506304286916\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy_count_lc = train_model(linear_model.LogisticRegression(), xtrain_count, train_labels, xvalid_count)\n",
    "print (\"LR, Count Vectors: \", accuracy_count_lc)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy_word_lc = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy_word_lc)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectorstrain_labels\n",
    "accuracy_ngram_lc = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_labels, xvalid_tfidf_ngram)\n",
    "print (\"LR, N-Gram Vectors: \", accuracy_ngram_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM,Count Vectors:  0.8257214906136172\n",
      "SVM, Word Level TF-IDF Vectors:  0.8318856822639394\n",
      "SVM, N-Gram Vectors:  0.8220790137293359\n"
     ]
    }
   ],
   "source": [
    "# SVM on Count Vectors Linear Kernel\n",
    "accuracy_count_svm = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_count, train_labels, xvalid_count)\n",
    "print (\"SVM,Count Vectors: \", accuracy_count_svm)\n",
    "\n",
    "# SVM on Word Level TF-IDF Vectors Linear Kernel\n",
    "accuracy_word_svm = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "print (\"SVM, Word Level TF-IDF Vectors: \", accuracy_word_svm)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors  Linear Kernel\n",
    "accuracy_ngram_svm = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_tfidf_ngram, train_labels, xvalid_tfidf_ngram)\n",
    "print (\"SVM, N-Gram Vectors: \", accuracy_ngram_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.7640795741103951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, WordLevel TF-IDF:  0.7663210983468759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Ngram Vectors:  0.7677220509946764\n"
     ]
    }
   ],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy_count_bg = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_labels, xvalid_count)\n",
    "print (\"RF, Count Vectors: \", accuracy_count_bg)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy_word_bg = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "print (\"RF, WordLevel TF-IDF: \", accuracy_word_bg)\n",
    "\n",
    "# RF on Ngram Vectors\n",
    "accuracy_ngram_bg = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_labels, xvalid_tfidf_ngram)\n",
    "print (\"RF, Ngram Vectors: \", accuracy_ngram_bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Count Vectors:  0.7752871952927991\n",
      "Xgb, WordLevel TF-IDF:  0.7867750070047632\n",
      "Xgb, Ngram Level Vectors:  0.7878957691230036\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy_count_bo = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_labels, xvalid_count.tocsc())\n",
    "print (\"Xgb, Count Vectors: \", accuracy_count_bo)\n",
    "\n",
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy_word_bo = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_labels, xvalid_tfidf.tocsc())\n",
    "print (\"Xgb, WordLevel TF-IDF: \", accuracy_word_bo)\n",
    "\n",
    "# Extereme Gradient Boosting on NGRAM Level TF IDF Vectors\n",
    "accuracy_ngram_bo = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram.tocsc(), train_labels, xvalid_tfidf_ngram.tocsc())\n",
    "print (\"Xgb, Ngram Level Vectors: \", accuracy_ngram_bo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  72.85 %\n",
      "\n",
      "Random Forest Classifier\n",
      "RF, Count Vectors:  79.6 %\n",
      "\n",
      "Linear Classifier\n",
      "LR, Count Vectors:  83.27 %\n",
      "\n",
      "SVM Classifier\n",
      "SVM,Count Vectors:  82.57 %\n",
      "\n",
      "Bagging Classifier\n",
      "RF, Count Vectors:  76.41 %\n",
      "\n",
      "Boosting Classifier\n",
      "Xgb, Count Vectors:  77.53 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('Naive Bayes Classifier')\n",
    "print (\"NB, Count Vectors: \", round(accuracy_count_nb*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print(\"RF, Count Vectors: \",round(accuracy_count_rf*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Linear Classifier')\n",
    "print (\"LR, Count Vectors: \", round(accuracy_count_lc*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('SVM Classifier')\n",
    "print (\"SVM,Count Vectors: \", round(accuracy_count_svm*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Bagging Classifier')\n",
    "print (\"RF, Count Vectors: \", round(accuracy_count_bg*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Boosting Classifier')\n",
    "print (\"Xgb, Count Vectors: \", round(accuracy_count_bo*100,2),\"%\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word Level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "NB, WordLevel TF-IDF:  71.76 %\n",
      "\n",
      "Random Forest Classifier\n",
      "RF, WordLevel TF-IDF Vectors:  79.46 %\n",
      "\n",
      "Linear Classifier\n",
      "LR, WordLevel TF-IDF:  81.48 %\n",
      "\n",
      "SVM Classifier\n",
      "SVM, Word Level TF-IDF Vectors:  83.19 %\n",
      "\n",
      "Bagging Classifier\n",
      "RF, WordLevel TF-IDF:  76.63 %\n",
      "\n",
      "Boosting Classifier\n",
      "Xgb, WordLevel TF-IDF:  78.68 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes Classifier')\n",
    "print (\"NB, WordLevel TF-IDF: \", round(accuracy_word_nb*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print(\"RF, WordLevel TF-IDF Vectors: \",round(accuracy_word_rf*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Linear Classifier')\n",
    "print (\"LR, WordLevel TF-IDF: \", round(accuracy_word_lc*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('SVM Classifier')\n",
    "print (\"SVM, Word Level TF-IDF Vectors: \", round(accuracy_word_svm*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Bagging Classifier')\n",
    "print (\"RF, WordLevel TF-IDF: \", round(accuracy_word_bg*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Boosting Classifier')\n",
    "print (\"Xgb, WordLevel TF-IDF: \", round(accuracy_word_bo*100,2),\"%\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using N-Gram Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "NB, Ngram Vectors:  72.71 %\n",
      "\n",
      "Random Forest Classifier\n",
      "RF, Ngram Vectors:  80.41 %\n",
      "\n",
      "Linear Classifier\n",
      "LR, Ngram Vectors:  80.98 %\n",
      "\n",
      "SVM Classifier\n",
      "SVM, Ngram Vectors:  82.21 %\n",
      "\n",
      "Bagging Classifier\n",
      "RF, Ngram Vectors:  76.77 %\n",
      "\n",
      "Boosting Classifier\n",
      "Xgb, Ngram Vectors:  78.79 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes Classifier')\n",
    "print (\"NB, Ngram Vectors: \", round(accuracy_ngram_nb*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print(\"RF, Ngram Vectors: \",round(accuracy_ngram_rf*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Linear Classifier')\n",
    "print (\"LR, Ngram Vectors: \", round(accuracy_ngram_lc*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('SVM Classifier')\n",
    "print (\"SVM, Ngram Vectors: \", round(accuracy_ngram_svm*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Bagging Classifier')\n",
    "print (\"RF, Ngram Vectors: \", round(accuracy_ngram_bg*100,2),\"%\")\n",
    "print(\"\")\n",
    "\n",
    "print('Boosting Classifier')\n",
    "print (\"Xgb, Ngram Vectors: \", round(accuracy_ngram_bo*100,2),\"%\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='linear'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.001}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_selection(xtrain_tfidf,train_labels,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Word Level TF-IDF Vectors:  83.19 %\n"
     ]
    }
   ],
   "source": [
    "# SVM on Word Level TF-IDF Vectors Linear Kernel\n",
    "accuracy_word_svm = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma=0.001), xtrain_tfidf, train_labels, xvalid_tfidf)\n",
    "print (\"SVM, Word Level TF-IDF Vectors: \", round(accuracy_word_svm*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion Matrix Using Logistic Regression on Word Level TF-IDF\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_cm(X, y, clf, title):\n",
    "\n",
    "    cm = metrics.confusion_matrix(y, clf.predict(X))\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "    mpl.rc(\"figure\", figsize=(8, 4))\n",
    "\n",
    "    hm = sns.heatmap(cm, \n",
    "            cbar=False,\n",
    "            annot=True, \n",
    "            square=True,\n",
    "            fmt='d',\n",
    "            yticklabels=['negative','neutral','positive'],\n",
    "            xticklabels=['negative','neutral','positive'],\n",
    "            cmap='Blues'\n",
    "            )\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Actual class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "claf = svm.SVC(C=1.0, kernel='linear', degree=3, gamma=0.001)\n",
    "claf.fit(xtrain_tfidf, train_labels)\n",
    "plot_cm(xtrain_tfidf, train_labels, claf, 'Training Word Level - TfidfVectorizer on Support Vector Machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(xvalid_tfidf,test_labels, claf, 'Testing Word Level - TfidfVectorizer on Support Vector Machine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
